
[English](./README.md) | [ç®€ä½“ä¸­æ–‡](./README_zh.md) 

# 1ã€é¡¹ç›®åŠŸèƒ½
é€šè¿‡è¯¥ä»£ç†æœåŠ¡ï¼Œæˆ‘ä»¬èƒ½å¤Ÿè½»æ¾è®°å½•å’Œå¤§æ¨¡å‹äº¤äº’çš„å‚æ•°åŠå…¶è¿”å›ç»“æœï¼Œä»è€Œä¾¿æ·åœ°åˆ†æå‡ºå®¢æˆ·ç«¯è°ƒç”¨å¤§æ¨¡å‹çš„é€»è¾‘ï¼Œæ·±å…¥ç†è§£ç°è±¡åŠå…¶æœ¬è´¨ã€‚
æœ¬é¡¹ç›®ä¸æ˜¯ä¸ºäº†ä¼˜åŒ–å¤§æ¨¡å‹çš„,ä½†å¯ä»¥åŠ©ä½ æ­å¼€å¤§æ¨¡å‹çš„ç¥ç§˜é¢çº±,ç†è§£å¹¶å®ç°äº§å“å¸‚åœºå¥‘åˆï¼ˆPMFï¼‰

MCPä¹Ÿæ˜¯LLMä¸­é‡è¦çš„ä¸€ç¯,æ•…æ­¤é¡¹ç›®ä¹Ÿå¯å½“ç”¨åšmcpå®¢æˆ·ç«¯ä½¿ç”¨,å¹¶æ”¯æŒå¯¹sse/mcp-streamable-httpæ¨¡å¼çš„æ£€æµ‹

# ğŸŒŸ ä¸»è¦ç‰¹æ€§
### åŠŸèƒ½åˆ—è¡¨:	
1. **mcpå®¢æˆ·ç«¯(å·²æ”¯æŒstdio/sse/streamableHttpè°ƒç”¨)**
2. **mcpåˆå§‹åŒ–æ£€æµ‹åˆ†æ(æ¯”å¦‚Cherry Studioæ”¯æŒstdio/sse/streamableHttp)**
3. **æ£€æµ‹ollama/openaiæ¥å£å¹¶ç”Ÿæˆåˆ†ææ—¥å¿—**
4. **mock ollama/openai æ¥å£æ•°æ®**
	
### æŠ€æœ¯ç‰¹ç‚¹:	
1. **uvå·¥å…·ä½¿ç”¨**
2. **uvicornæ¡†æ¶ä½¿ç”¨**
3. **å‰ç«¯asyncã€åç«¯async**
4. **æ—¥å¿—æ˜¾ç¤ºå®æ—¶åˆ·æ–°ï¼Œæ–­ç‚¹ç»­è”**
5. **py socketå†™httpå®¢æˆ·ç«¯ï¼Œæ”¯æŒget/post,åŠå„è‡ªæµå¼è¾“å‡º**
6. **webSocketç»“åˆasyncioä¸€èµ·ä½¿ç”¨**
7. **threading/queueä½¿ç”¨**
8. **pyç¨‹åºæ‰“åŒ…æˆexe**

# 2ã€é¡¹ç›®èƒŒæ™¯
åœ¨çœŸæ­£çš„AGIåˆ°æ¥ä¹‹å‰ï¼Œæˆ‘ä»¬å¿…å°†ç»å†ä¸€æ®µæ¼«é•¿çš„æ—…ç¨‹ï¼ŒæœŸé—´éœ€è¦ä¸æ–­é¢å¯¹æŒ‘æˆ˜ï¼Œæ— è®ºæ˜¯æ™®é€šäººè¿˜æ˜¯ä¸“ä¸šäººå£«ï¼Œç”Ÿæ´»éƒ½å°†å› æ­¤è€Œæ”¹å˜ã€‚

ç„¶è€Œï¼Œå¯¹äºå¤§æ¨¡å‹çš„ä½¿ç”¨ï¼Œæ— è®ºæ˜¯æ™®é€šç”¨æˆ·è¿˜æ˜¯å¼€å‘äººå‘˜ï¼Œå¾€å¾€éƒ½æ˜¯é€šè¿‡å„ç§å®¢æˆ·ç«¯é—´æ¥æ¥è§¦çš„ã€‚ä½†å®¢æˆ·ç«¯å¾€å¾€å±è”½äº†å’Œå¤§æ¨¡å‹äº¤äº’çš„è¿‡ç¨‹ï¼Œå¯ä»¥ç›´æ¥æ ¹æ®ç”¨æˆ·çš„ç®€å•è¾“å…¥ï¼Œ
å°±ç»™å‡ºç»“æœï¼Œç»™äººä¸€ç§æ„Ÿè§‰å°±æ˜¯å¤§æ¨¡å‹å¾ˆç¥ç§˜ï¼Œåƒé»‘ç›’ä¸€æ ·ã€‚ å®é™…ä¸æ˜¯è¿™æ ·çš„ï¼Œä½¿ç”¨å¤§æ¨¡å‹ï¼Œç®€å•ç†è§£æˆ‘ä»¬å°±æ˜¯åœ¨è°ƒç”¨ä¸€ä¸ªæ¥å£ï¼Œæœ‰è¾“å…¥è¾“å‡ºç½¢äº†ã€‚
éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå°½ç®¡è®¸å¤šæ¨ç†å¹³å°æä¾›äº†OpenAIæ ¼å¼çš„æ¥å£ï¼Œä½†å®ƒä»¬çš„å®é™…æ”¯æŒæƒ…å†µå„ä¸ç›¸åŒï¼Œç®€å•æ¥è¯´ï¼ŒAPIçš„è¯·æ±‚å‚æ•°å’Œè¿”å›å‚æ•°å¹¶ä¸å®Œå…¨ä¸€è‡´ã€‚

è‹¥æƒ³äº†è§£è¯¦ç»†å‚æ•°æ”¯æŒæƒ…å†µï¼Œè¯·çœ‹

[å‡†æ ‡å‡†:OpenAI API](https://platform.openai.com/docs/api-reference/responses/create)

[å¼€å‘ç¯å¢ƒå¸¸ç”¨:OLLAMA API](https://github.com/ollama/ollama/blob/main/docs/openai.md#supported-features)

[ç”Ÿäº§ç¯å¢ƒå¸¸ç”¨:VLLM API](https://docs.vllm.ai/en/stable/api/inference_params.html#sampling-parameters)

å…¶ä»–å¹³å°è¯·è‡ªè¡ŒæŸ¥é˜…

### æœ¬é¡¹ç›®é‡‡ç”¨uvicornæ¡†æ¶å¯åŠ¨asgiæä¾›APIæœåŠ¡ï¼Œä»¥æœ€å°çš„ä¾èµ–ï¼Œå¿«é€Ÿè€Œç®€æ´åœ°è¿è¡Œï¼Œè‡´æ•¬ç»å…¸

# 3ã€å®‰è£…

```sh

# å…‹éš†ä»“åº“
git clone https://github.com/xuzexin-hz/llm-analysis-assistant.git
cd llm-analysis-assistant

# å®‰è£…æ‰©å±•
uv sync

```

# 4ã€ä½¿ç”¨
è¿›å…¥æ ¹ç›®å½•ï¼Œç„¶åè¿›å…¥binç›®å½•
ç‚¹å‡»run-server.cmd,å°±å¯ä»¥å¯åŠ¨æœåŠ¡
ç‚¹å‡»run-build.cmd,å³å¯æŠŠè¯¥æœåŠ¡æ‰“åŒ…æˆå¯æ‰§è¡Œæ–‡ä»¶(åœ¨distç›®å½•ä¸­)

æˆ–è€…åœ¨è·Ÿç›®å½•ç›´æ¥è¿è¡Œä»¥ä¸‹å‘½ä»¤:

```sh

#é»˜è®¤8000ç«¯å£
python server.py

#ä¹Ÿå¯ä»¥æŒ‡å®šç«¯å£
python server.py --port=8001

#ä¹Ÿå¯ä»¥æŒ‡å®šopenaiåœ°å€,é»˜è®¤æ˜¯ollamaçš„åœ°å€ï¼šhttp://127.0.0.1:11434/v1/
python server.py --base_url=https://api.openai.com
#è‹¥é…ç½®å…¶ä»–apiåœ°å€ï¼Œè®°å¾—è¦å¡«å†™å‡†ç¡®çš„api_key,ollamaé»˜è®¤æ˜¯ä¸éœ€è¦api_keyçš„

#--is_mock=true å¼€å¯mockï¼Œå¯ä»¥è¿”å›æ¨¡æ‹Ÿæ•°æ®
python server.py --is_mock=true

#--mock_stringï¼Œå¯ä»¥è‡ªå®šä¹‰è¿”å›æ¨¡æ‹Ÿæ•°æ®ï¼Œä¸è®¾ç½®æ­¤é¡¹å°±ä¼šè¿”å›é»˜è®¤mockæ•°æ®.æ­¤å‚æ•°å¯¹éæµå¼è¾“å‡ºä¹Ÿé€‚ç”¨
python server.py --is_mock=true --mock_string=ä½ å¥½å•Š

#--mock_countï¼Œmockæµå¼è¾“å‡ºæ—¶è¿”å›æ•°æ®çš„æ¬¡æ•°ï¼Œé»˜è®¤3æ¬¡
python server.py --is_mock=true --mock_string=ä½ å¥½å•Š --mock_count=10

#--single_wordï¼Œmockæµå¼è¾“å‡ºæ—¶è¿”å›æ•ˆæœ,é»˜è®¤æ˜¯æŠŠä¸€å¥è¯æŒ‰ã€2:5:3ã€‘åˆ†3éƒ¨åˆ†ä¾æ¬¡è¿”å›,è®¾ç½®æ¬¡å‚æ•°åå°±æ˜¯ä¸€ä¸ªå­—ä¸€ä¸ªå­—çš„æµå¼è¾“å‡ºæ•ˆæœ
python server.py --is_mock=true --mock_string=ä½ å¥½å•Š --single_word=true

#--looptimeï¼Œmockæµå¼è¾“å‡ºæ—¶è¿”å›æ•°æ®çš„é—´éš”æ—¶é—´ï¼Œé»˜è®¤æ˜¯0.35ç§’,è®¾ç½®looptime=1åæµå¼è¾“å‡ºæ—¶å€™æ˜¾ç¤ºæ•°æ®é€Ÿåº¦å°±ä¼šæ…¢
python server.py --is_mock=true --mock_string=ä½ å¥½å•Š --looptime=1

```

### ä½¿ç”¨ PIP(ğŸŒŸ)

æˆ–è€…ï¼Œæ‚¨å¯ä»¥é€šè¿‡ pip å®‰è£… 'llm-analysis-assistant':

```
pip install llm-analysis-assistant
```

å®‰è£…åï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹è„šæœ¬è¿è¡Œå®ƒ:

```
python -m llm_analysis_assistant
```

http://127.0.0.1:8000/logs å®æ—¶æŸ¥çœ‹æ—¥å¿—

# æ£€æµ‹åˆ†æå¹¶è°ƒç”¨mcp(ç›®å‰å·²æ”¯æŒstdio/sse/streamableHttp)

mcpå®¢æˆ·ç«¯æŠ€æœ¯å®ç°é€»è¾‘å¦‚ä¸‹,çœ‹æ¥å£æ—¥å¿—ä¼¼ä¹æ˜¯é¡ºåºè¯·æ±‚,ä½†å®é™…ç¡®ä¸æ˜¯è¿™æ ·çš„,ä¸æ˜¯ç®€å•çš„è¯·æ±‚-å“åº”æ¨¡å¼,è¿™æ ·å¤„ç†æ˜¯ä¾¿äºç”¨æˆ·ç†è§£

![mcp.png](docs/imgs/mcp.png)

mcp-sseé€»è¾‘ç»†èŠ‚(å’Œstdio/streamableHttpçš„å¼‚åŒç‚¹å¯å‚è€ƒå…¶ä»–èµ„æ–™äº†è§£)

![mcp-sse.png](docs/imgs/mcp-sse.png)

# æ£€æµ‹åˆ†æmcp-stdio
æµè§ˆå™¨æ‰“å¼€ä¸‹é¢åœ°å€,å‘½ä»¤è¡Œä¸­++user=xxx è¡¨ç¤ºç³»ç»Ÿå˜é‡æ˜¯user,å€¼æ˜¯xxx

http://127.0.0.1:8000/mcp?url=stdio

æˆ–è€…ä½¿ç”¨Cherry Studioæ·»åŠ stdioæœåŠ¡

![Cherry-Studio-mcp-stdio.png](docs/imgs/Cherry-Studio-mcp-stdio.png)

# æ£€æµ‹åˆ†æmcp-sse
æµè§ˆå™¨æ‰“å¼€ä¸‹é¢åœ°å€ï¼Œurlä¸ºsseæœåŠ¡åœ°å€

http://127.0.0.1:8000/mcp?url=http://127.0.0.1:8001/sse

æˆ–è€…ä½¿ç”¨Cherry Studioæ·»åŠ mcpæœåŠ¡

![Cherry-Studio-mcp-sse.png](docs/imgs/Cherry-Studio-mcp-sse.png)

# æ£€æµ‹åˆ†æmcp-streamable-http
æµè§ˆå™¨æ‰“å¼€ä¸‹é¢åœ°å€ï¼Œurlä¸ºstreamableHttpæœåŠ¡åœ°å€

http://127.0.0.1:8000/mcp?url=http://127.0.0.1:8001/mcp

æˆ–è€…ä½¿ç”¨Cherry Studioæ·»åŠ mcpæœåŠ¡

![mcp-streamable-http.png](docs/imgs/mcp-streamable-http.png)

ä½¿ç”¨Cherry Studioæ—¶å¯é€šè¿‡ http://127.0.0.1:8000/logs  å®æ—¶æŸ¥çœ‹æ—¥å¿—æ¥åˆ†æsse/mcp-streamable-httpçš„è°ƒç”¨é€»è¾‘

# 5ã€ä¾‹å­é›†åˆ
ç»Ÿä¸€æŠŠopenaiçš„base_urlæ”¹æˆè¯¥æœåŠ¡çš„åœ°å€ï¼šhttp://127.0.0.1:8000
### â‘´ã€ åˆ†ælangchain
### å…ˆå®‰è£…langchain:
```sh

pip install langchain langchain-openai

```

```sh

from langchain.chat_models import init_chat_model
model = init_chat_model("qwen2.5-coder:1.5b", model_provider="openai",base_url='http://127.0.0.1:8000',api_key='ollama')
model.invoke("Hello, world!")

```
##### è¿è¡Œä¸Šé¢ä»£ç åï¼Œè¦æƒ³æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶ï¼Œå¯ä»¥è¿›å…¥logsç›®å½•å¯¹åº”å¤©æ•°æ–‡ä»¶å¤¹ä¸­æŸ¥çœ‹ï¼Œæ¯ä¸€ä¸ªè¯·æ±‚ä¸€ä¸ªlogæ–‡ä»¶
##### æ‰“å¼€[http://127.0.0.1:8000/logs](http://127.0.0.1:8000/logs)å¯å®æ—¶æŸ¥çœ‹æ—¥å¿—

### â‘µåˆ†æå·¥å…·é›†
#### 1ã€å·¥å…·Open WebUI
[Open WebUI.md](docs/Open%20WebUI.md)

#### 2ã€å·¥å…·Cherry Studio
[Cherry Studio.md](docs/Cherry%20Studio.md)

#### 3ã€å·¥å…·continue
[continue.md](docs/continue.md)

#### 4ã€å·¥å…·Navicat
[Navicat.md](docs/Navicat.md)

### â‘¶ã€ åˆ†ææ™ºèƒ½ä½“
#### 1ã€æ™ºèƒ½ä½“ Multi-Agent Supervisor

###### agentå³èŠ‚ç‚¹ï¼Œagentå³å·¥å…·ï¼Œé¢†å¯¼è€…æ¨¡å¼

![langgraph-supervisor1.png](docs/imgs/langgraph-supervisor1.png)

[langgraph-supervisor.md](docs/langgraph-supervisor.md)

#### 2ã€æ™ºèƒ½ä½“ Multi-Agent Swarm
###### ä¸“ä¸šçš„äº‹äº¤ç»™ä¸“ä¸šçš„äººæ‰å¯é ï¼Œå›¢é˜Ÿåˆä½œæ¨¡å¼

![langgraph-swarm1.png](docs/imgs/langgraph-swarm1.png)

[langgraph-swarm.md](docs/langgraph-swarm.md)

####  3ã€æ™ºèƒ½ä½“ codeact
###### å°ºæœ‰æ‰€çŸ­,å¯¸æœ‰æ‰€é•¿å˜›(æ®è¯´CodeActåœ¨ä¸€äº›åœºæ™¯ä¸‹å‡†ç¡®æ€§å’Œæ•ˆç‡ä¼šå¤§å¹…æé«˜)

![langgraph-codeact1.png](docs/imgs/langgraph-codeact1.png)

[langgraph-codeact.md](docs/langgraph-codeact.md)

# License
[Apache 2.0 License.](LICENSE)